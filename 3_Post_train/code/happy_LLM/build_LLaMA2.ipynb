{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "参数配置,用于后续创建模型",
   "id": "9547bcc78c575902"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.303887Z",
     "start_time": "2025-12-18T12:28:19.991790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import PretrainedConfig\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers.models.llama4.modeling_llama4 import reshape_for_broadcast\n",
    "from typing import Tuple\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "class ModelConfig(PretrainedConfig):\n",
    "    model_type = \"Tiny-K\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dim: int = 768,  # 模型维度\n",
    "            n_layers: int = 12,  # Transformer的层数\n",
    "            n_heads: int = 16,  # 注意力机制的头数\n",
    "            n_kv_heads: int = 8,  # 键值头的数量\n",
    "            vocab_size: int = 6144,  # 词汇表大小\n",
    "            hidden_dim: int = None,  # 隐藏层维度\n",
    "            multiple_of: int = 64,\n",
    "            norm_eps: float = 1e-5,  # 归一化层的eps\n",
    "            max_seq_len: int = 512,  # 最大序列长度\n",
    "            dropout: float = 0.0,  # dropout概率\n",
    "            flash_attn: bool = True,  # 是否使用Flash Attention\n",
    "            **kwargs,\n",
    "    ):\n",
    "        self.dim = dim\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.n_kv_heads = n_kv_heads\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.multiple_of = multiple_of\n",
    "        self.norm_eps = norm_eps\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.dropout = dropout\n",
    "        self.flash_attn = flash_attn\n",
    "        super().__init__(**kwargs)"
   ],
   "id": "b82f53c621439b58",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\python\\conda\\envs\\lightning_learn\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "RMSNorm",
   "id": "9f292909e3d0f3f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.350826Z",
     "start_time": "2025-12-18T12:28:26.313939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.g = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        # 计算RMSNorm的核心部分\n",
    "        # x.pow(2).mean(-1, keepdim=True)计算了输入x的平方的均值\n",
    "        # torch.rsqrt是平方根的倒数，这样就得到了RMSNorm的分母部分，再加上eps防止分母为0\n",
    "        # 最后乘以x，得到RMSNorm的结果\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward函数是模型的前向传播\n",
    "        # 首先将输入x转为float类型，然后进行RMSNorm，最后再转回原来的数据类型\n",
    "        # 最后乘以weight，这是RMSNorm的一个可学习的缩放因子\n",
    "        # 当模型使用混合精度（如 torch.float16/torch.bfloat16）训练时，\n",
    "        # 直接用低精度计算平方均值可能导致数值下溢（小数值的平方会变成 0），\n",
    "        # 进而引发归一化后的梯度爆炸 / NaN；\n",
    "        x = self._norm(x.float()).type_as(x)\n",
    "        return self.g * x\n",
    "\n",
    "\n",
    "args = ModelConfig()\n",
    "norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "x = torch.randn(2, 3, args.dim)\n",
    "print(x.shape, norm(x).shape)"
   ],
   "id": "6571875e80ab4e81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768]) torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 构建LLaMA2 Attention\n",
    "使用GQA (Grouped-Query Attention)\n",
    "<img src=\"./LLaMA2_Attention.png\" width=\"320\" height=\"240\">\n"
   ],
   "id": "8eea6334142cf022"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.380729Z",
     "start_time": "2025-12-18T12:28:26.363731Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f83daa268edce2b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "GQA将多个Q成组,因此需要重复KV n次",
   "id": "334dbe4bed654345"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.395948Z",
     "start_time": "2025-12-18T12:28:26.389947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    bs, slen, n_kv_heads, head_dim = x.shape\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "\n",
    "    # 逻辑：(B, S, H, D) -> (B, S, H, 1, D) -> (B, S, H, R, D) -> (B, S, H*R, D)\n",
    "    return (\n",
    "        # 使用None索引使得维度匹配,从而执行expand操作\n",
    "        x[:, :, :, None, :]\n",
    "        .expand(bs, slen, n_kv_heads, n_rep, head_dim)\n",
    "        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)\n",
    "    )"
   ],
   "id": "51cf849f8a86a625",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 旋转位置编码(Rotary Positional Embedding, RoPE)\n",
    "![image.png](./RoPE.png)"
   ],
   "id": "17a23f44ab037543",
   "attachments": {
    "45acbe6b-733f-4e88-88c2-33a46c07f203.png": {
     "image/png": "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"
    }
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.411016Z",
     "start_time": "2025-12-18T12:28:26.403010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    # torch.arange(0, dim, 2)[: (dim // 2)].float()生成了一个从0开始，步长为2的序列，长度为dim的一半\n",
    "    # 然后每个元素除以dim，再取theta的倒数，得到频率\n",
    "    # -2(i-1)/d\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2) / dim))\n",
    "    t = torch.arange(end, device=freqs.device)\n",
    "    # 计算外积，得到一个二维矩阵，每一行是t的元素乘以freqs的元素\n",
    "    freqs = torch.outer(t, freqs)\n",
    "    # 计算频率的余弦值，得到实部\n",
    "    freqs_cos = torch.cos(freqs)\n",
    "    # 计算频率的正弦值，得到虚部\n",
    "    freqs_sin = torch.sin(freqs)\n",
    "    return freqs_cos, freqs_sin"
   ],
   "id": "31634073b5619e15",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.426710Z",
     "start_time": "2025-12-18T12:28:26.418077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_rotary_emb(\n",
    "        xq: torch.Tensor,\n",
    "        xk: torch.Tensor,\n",
    "        freqs_cos: torch.Tensor,\n",
    "        freqs_sin: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    # 将查询和键张量转换为浮点数，并重塑形状以分离实部和虚部\n",
    "    xq_r, xq_i = xq.float().reshape(xq.shape[:-1] + (-1, 2)).unbind(-1)\n",
    "    xk_r, xk_i = xk.float().reshape(xk.shape[:-1] + (-1, 2)).unbind(-1)\n",
    "\n",
    "    freqs_cos, freqs_sin = reshape_for_broadcast(freqs_cos, xq_r), reshape_for_broadcast(freqs_sin, xq_r)\n",
    "    # 应用旋转，分别计算旋转后的实部和虚部\n",
    "    xq_out_r = xq_r * freqs_cos - xq_i * freqs_sin\n",
    "    xq_out_i = xq_r * freqs_sin + xq_i * freqs_cos\n",
    "    xk_out_r = xk_r * freqs_cos - xk_i * freqs_sin\n",
    "    xk_out_i = xk_r * freqs_sin + xk_i * freqs_cos\n",
    "    # 将最后两个维度合并，并还原为原始张量的形状\n",
    "    xq_out = torch.stack([xq_out_r, xq_out_i], dim=-1).flatten(3)\n",
    "    xk_out = torch.stack([xk_out_r, xk_out_i], dim=-1).flatten(3)\n",
    "\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)"
   ],
   "id": "80a2f15b93027924",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.473134Z",
     "start_time": "2025-12-18T12:28:26.433710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xq = torch.randn(1, 50, 6, 48)  # bs, seq_len, dim//n_head, n_head_dim\n",
    "xk = torch.randn(1, 50, 6, 48)  # bs, seq_len, dim//n_head, n_head_dim\n",
    "\n",
    "# 使用 precompute_freqs_cis 函数获取 sin和cos\n",
    "cos, sin = precompute_freqs_cis(288 // 6, 50)\n",
    "print(cos.shape, sin.shape)\n",
    "xq_out, xk_out = apply_rotary_emb(xq, xk, cos, sin)\n",
    "\n",
    "xq_out.shape, xk_out.shape\n"
   ],
   "id": "fc6feea443cd7d2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 24]) torch.Size([50, 24])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50, 6, 48]), torch.Size([1, 50, 6, 48]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Attention",
   "id": "df0fe18c1e74dd1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.504200Z",
     "start_time": "2025-12-18T12:28:26.487610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelConfig):\n",
    "        super().__init__()\n",
    "        # 是否使用kv head\n",
    "        self.n_kv_heads = args.n_kv_heads if args.n_kv_heads is not None else args.n_heads\n",
    "        # 模型并行处理大小，默认为1。\n",
    "        model_parallel_size = 1\n",
    "        # 本地计算头数，等于总头数除以模型并行处理大小。\n",
    "        self.n_local_heads = args.n_heads // model_parallel_size\n",
    "        self.n_local_kv_heads = self.n_kv_heads // model_parallel_size\n",
    "\n",
    "        # 本地计算头数，等于总头数除以模型并行处理大小。\n",
    "        self.n_rep = self.n_local_heads // self.n_local_kv_heads\n",
    "\n",
    "        # 每个头的维度，等于模型维度除以头的总数\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)\n",
    "\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "        self.attn_dropout = nn.Dropout(args.dropout)\n",
    "        self.resid_dropout = nn.Dropout(args.dropout)\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "        # 检查是否使用Flash Attention（需要PyTorch >= 2.0）。\n",
    "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
    "        if not self.flash:\n",
    "            # 若不支持Flash Attention，则使用手动实现的注意力机制，并设置mask。\n",
    "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
    "            # 创建一个上三角矩阵，用于遮蔽未来信息。\n",
    "            mask = torch.full((1, 1, args.max_seq_len, args.max_seq_len), float(\"-inf\"))\n",
    "            mask = torch.triu(mask, diagonal=1)\n",
    "            # 注册为模型的缓冲区\n",
    "            self.register_buffer(\"mask\", mask)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, freqs_cos: torch.Tensor, freqs_sin: torch.Tensor):\n",
    "        # [batch_size, seq_len, dim]\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\n",
    "        # RoPE\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cos, freqs_sin)\n",
    "\n",
    "        xk = repeat_kv(xk, self.n_rep)\n",
    "        xv = repeat_kv(xv, self.n_rep)\n",
    "\n",
    "        # 将头作为批次维度处理。\n",
    "        xq = xq.transpose(1, 2)\n",
    "        xk = xk.transpose(1, 2)\n",
    "        xv = xv.transpose(1, 2)\n",
    "        # 根据是否支持Flash Attention，选择实现方式。\n",
    "        if self.flash:\n",
    "            # 使用Flash Attention。\n",
    "            output = torch.nn.functional.scaled_dot_product_attention(xq, xk, xv, attn_mask=None,\n",
    "                                                                      dropout_p=self.dropout if self.training else 0.0,\n",
    "                                                                      is_causal=True)\n",
    "        else:\n",
    "            # 使用手动实现的注意力机制。\n",
    "            scores = torch.matmul(xq, xk.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "            assert hasattr(self, 'mask')\n",
    "            scores = scores + self.mask[:, :, :seqlen, :seqlen]\n",
    "            scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "            scores = self.attn_dropout(scores)\n",
    "            output = torch.matmul(scores, xv)\n",
    "\n",
    "        # 恢复时间维度并合并头。\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        # 最终投影回残差流。\n",
    "        output = self.wo(output)\n",
    "        output = self.resid_dropout(output)\n",
    "        return output"
   ],
   "id": "db7ac83e50451e16",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.567836Z",
     "start_time": "2025-12-18T12:28:26.513001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建Attention实例\n",
    "attention_model = Attention(args)\n",
    "\n",
    "# 模拟输入数据\n",
    "batch_size = 1\n",
    "seq_len = 50  # 假设实际使用的序列长度为50\n",
    "dim = args.dim\n",
    "x = torch.rand(batch_size, seq_len, dim)  # 随机生成输入张量\n",
    "freqs_cos = torch.rand(seq_len, dim // 2)  # 模拟cos频率，用于RoPE\n",
    "freqs_sin = torch.rand(seq_len, dim // 2)  # 模拟sin频率，用于RoPE\n",
    "\n",
    "freqs_cos, freqs_sin = precompute_freqs_cis(dim // args.n_heads, seq_len)\n",
    "\n",
    "# 运行Attention模型\n",
    "output = attention_model(x, freqs_cos, freqs_sin)\n",
    "\n",
    "# attention出来之后的形状 依然是[batch_size, seq_len, dim]\n",
    "print(\"Output shape:\", output.shape)\n"
   ],
   "id": "de42dd09eb3bebb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 50, 768])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LLaMA2的MLP",
   "id": "9cd5b37759f26802"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.600052Z",
     "start_time": "2025-12-18T12:28:26.577928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim: int, hidden_dim: int, multiple_of: int, dropout: float):\n",
    "        super().__init__()\n",
    "        # 如果没有指定隐藏层的维度，我们将其设置为输入维度的4倍\n",
    "        # 然后将其减少到2/3，最后确保它是multiple_of的倍数\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = 4 * dim\n",
    "            hidden_dim = int(2 * hidden_dim / 3)\n",
    "            hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "        # 定义第一层线性变换，从输入维度到隐藏维度\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        # 定义第二层线性变换，从隐藏维度到输入维度\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        # 定义第三层线性变换，从输入维度到隐藏维度\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        # 定义dropout层，用于防止过拟合\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数\n",
    "        # 首先，输入x通过第一层线性变换和SILU激活函数\n",
    "        # 然后，结果乘以输入x通过第三层线性变换的结果\n",
    "        # 最后，通过第二层线性变换和dropout层\n",
    "        return self.dropout(self.w2(F.silu(self.w1(x)) * self.w3(x)))\n"
   ],
   "id": "6cd68f058d899746",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.648142Z",
     "start_time": "2025-12-18T12:28:26.609052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建MLP实例\n",
    "mlp = MLP(args.dim, args.hidden_dim, args.multiple_of, args.dropout)\n",
    "# 随机生成数据\n",
    "x = torch.randn(1, 50, args.dim)\n",
    "# 运行MLP模型\n",
    "output = mlp(x)\n",
    "# 输出和输入形状一致\n",
    "print(x.shape, output.shape)\n"
   ],
   "id": "75574c26185c173e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 768]) torch.Size([1, 50, 768])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Decoder",
   "id": "4d1a5cad327d674b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.663362Z",
     "start_time": "2025-12-18T12:28:26.654144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, layer_id, args: ModelConfig, ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = args.dim\n",
    "        self.attn = Attention(args)\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.feed_forward = MLP(args.dim, args.hidden_dim, args.multiple_of, args.dropout)\n",
    "        self.layer_id = layer_id\n",
    "        # 注意力计算的归一化层\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        # feed forward的归一化层\n",
    "        self.ff_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, freqs_cos: torch.Tensor, freqs_sin: torch.Tensor):\n",
    "        h = x + self.attn(self.attention_norm(x), freqs_cos, freqs_sin)\n",
    "        out = h + self.feed_forward(self.ff_norm(h))\n",
    "        return out"
   ],
   "id": "553b82333e9679e2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.726092Z",
     "start_time": "2025-12-18T12:28:26.670363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "decoder = DecoderLayer(1, args)\n",
    "x = torch.randn(1, 50, args.dim)\n",
    "freqs_cos, freqs_sin = precompute_freqs_cis(args.dim // args.n_heads, 50)\n",
    "out = decoder(x, freqs_cos, freqs_sin)\n",
    "print(x.shape, out.shape)"
   ],
   "id": "91bb3b28d83d6ed9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 768]) torch.Size([1, 50, 768])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:26.756677Z",
     "start_time": "2025-12-18T12:28:26.732098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers.modeling_outputs import  CausalLMOutputWithPast\n",
    "from typing import Optional\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "class Transformer(PreTrainedModel):\n",
    "    config_class = ModelConfig  # 配置类\n",
    "    last_loss: Optional[torch.Tensor] # 记录最后一次计算的损失\n",
    "    def __init__(self, args: ModelConfig):\n",
    "        super().__init__(args)\n",
    "        self.args=args\n",
    "        self.vocab_size = args.vocab_size\n",
    "        self.num_layers = args.n_layers\n",
    "        # embedding\n",
    "        self.tok_embeddings=nn.Embedding(args.vocab_size, args.dim)\n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "\n",
    "        # decoder\n",
    "        self.n_layers = args.n_layers\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for i in range(args.n_layers):\n",
    "            self.layers.append( DecoderLayer(i, args) )\n",
    "        self.norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.output = nn.Linear(args.dim, args.vocab_size, bias=False)\n",
    "        # 将词嵌入层的权重与输出层的权重共享,这里是一个经典的技巧，embedding和liner的形状一致，可以共享权重,具体不赘述\n",
    "        self.tok_embeddings.weight = self.output.weight\n",
    "\n",
    "        # 相对位置嵌入的频率,和torch.parameter不同,register_buffer的参数是无梯度不被训练的,用于记录常量,且模型保存时也会保存这部分参数\n",
    "        freqs_cos, freqs_sin = precompute_freqs_cis(self.args.dim // self.args.n_heads, self.args.max_seq_len)\n",
    "        self.register_buffer(\"freqs_cos\", freqs_cos, persistent=False)\n",
    "        self.register_buffer(\"freqs_sin\", freqs_sin, persistent=False)\n",
    "\n",
    "        # 初始化所有权重\n",
    "        self.apply(self._init_weights)\n",
    "         # 初始化最后一次前向传播的损失属性\n",
    "\n",
    "        # 对残差进行特殊的缩放初始化\n",
    "        for pn, p in self.named_parameters():\n",
    "            # wo.weight: 通常指 Attention 层的输出投影矩阵\n",
    "            # w3.weight 前馈神经网络（FFN/MLP）的下投影矩阵\n",
    "            # 为了防止随着网络层数变深，残差连接带来的信号方差（Variance）无限累积,在GPT2中也有相同的操作\n",
    "            if pn.endswith('w3.weight') or pn.endswith('wo.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * args.n_layers))\n",
    "\n",
    "        self.last_loss = None\n",
    "        # class transformers.modeling_outputs.CausalLMOutputWithPast\n",
    "        self.OUT = CausalLMOutputWithPast()  # 输出容器\n",
    "        self._no_split_modules = [name for name, _ in self.named_modules()]  # 不分割的模块列表\n",
    "\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        # 初始化权重\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, targets: Optional[torch.Tensor] = None,**kwargs)->torch.Tensor :\n",
    "        \"\"\"\n",
    "\n",
    "        :param x: input\n",
    "\n",
    "        self.OUT: CausalLMOutputWithPast, 包含 logits 和损失\n",
    "        \"\"\"\n",
    "        if 'input_ids' in kwargs:\n",
    "            x = kwargs['input_ids']\n",
    "        if 'attention_mask' in kwargs:\n",
    "            targets = kwargs['attention_mask']\n",
    "        _bsz,seqlen=x.shape\n",
    "        h=self.tok_embeddings(x)\n",
    "        h=self.dropout(h)\n",
    "        # 前seqlen项\n",
    "        freqs_cos, freqs_sin = self.freqs_cos[:seqlen], self.freqs_sin[:seqlen]\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, freqs_cos, freqs_sin)\n",
    "        h=self.norm(h)\n",
    "        if targets is not None:\n",
    "            # 训练\n",
    "            # 如果给定了目标，计算损失\n",
    "            logits = self.output(h)\n",
    "            self.last_loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=0, reduction='none')\n",
    "        else:\n",
    "            # 推理\n",
    "            # 推理时的小优化：只对最后一个位置的输出进行前向传播\n",
    "            # logits: [bsz, 1, vocab_size]\n",
    "            logits = self.output(h[:, [-1], :])\n",
    "            self.last_loss = None\n",
    "\n",
    "        # 设置输出\n",
    "        self.OUT.__setitem__('logits', logits)\n",
    "        self.OUT.__setitem__('last_loss', self.last_loss)\n",
    "        return self.OUT\n",
    "\n",
    "    # 仅用于推理,节省资源(不计算梯度等信息\n",
    "    @torch.inference_mode()\n",
    "    def generate(self, idx, stop_id=None, max_new_tokens=256, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        给定输入序列 idx（形状为 (bz,seq_len) 的长整型张量），通过多次生成新 token 来完成序列。\n",
    "        在 model.eval() 模式下运行。效率较低的采样版本，没有使用键k/v cache。\n",
    "        \"\"\"\n",
    "        index = idx.shape[1]\n",
    "        for _ in range(max_new_tokens):\n",
    "            # 如果序列上下文过长，截断它到最大长度\n",
    "            idx_cond = idx if idx.size(1) <= self.args.max_seq_len else idx[:, -self.args.max_seq_len:]\n",
    "\n",
    "            # 前向传播获取序列中最后一个位置的 logits\n",
    "            logits = self(idx_cond).logits\n",
    "            logits = logits[:, -1, :] # 只保留最后一个时间步的输出\n",
    "\n",
    "            if temperature == 0.0:\n",
    "                # 选择最有可能的索引\n",
    "                _, idx_next = torch.topk(logits, k=1, dim=-1)\n",
    "            else:\n",
    "                # 缩放 logits 并应用 softmax\n",
    "                logits = logits / temperature\n",
    "                if top_k is not None:\n",
    "                    v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                    logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "                idx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "\n",
    "            if idx_next == stop_id:\n",
    "                break\n",
    "\n",
    "            # 将采样的索引添加到序列中并继续\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx[:, index:] # 只返回生成的token"
   ],
   "id": "d00fcb328a57bd4b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:27.611882Z",
     "start_time": "2025-12-18T12:28:26.767685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=torch.randint(0,6144,(1,50))\n",
    "model=Transformer(args= args)\n",
    "# 计算全部参数\n",
    "num_params=sum(p.numel() for p in model.parameters())\n",
    "print(f'参数数量:{num_params}')\n",
    "\n",
    "out=model(x)\n",
    "print(out.logits.shape)"
   ],
   "id": "28f257e54afde994",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数数量:82594560\n",
      "torch.Size([1, 1, 6144])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T14:37:21.933893Z",
     "start_time": "2025-12-16T14:37:21.927375Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Tokenizer",
   "id": "776dfc193101e461"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "下面使用 Hugging Face 的 tokenizers 库来训练一个 BPE Tokenizer。",
   "id": "fae6640e19939f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:27.737573Z",
     "start_time": "2025-12-18T12:28:27.728189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    pre_tokenizers,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "from tokenizers.normalizers import NFKC\n",
    "from typing import Generator\n"
   ],
   "id": "b95cf77e33ba3665",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:27.753160Z",
     "start_time": "2025-12-18T12:28:27.744132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_texts_from_jsonl(file_path: str)-> Generator[str, None, None]:\n",
    "    \"\"\"\n",
    "    从 jsonl 文件中读取文本。\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line_num,line in enumerate(f,1):\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                if 'text' not in data:\n",
    "                    raise KeyError(f\"Missing 'text' field in line {line_num}\")\n",
    "                text = data['text']\n",
    "                yield text\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error decoding JSON in line {line_num}\")\n",
    "                continue\n",
    "            except KeyError as e:\n",
    "                print(e)\n",
    "                continue\n"
   ],
   "id": "c386ba40d7a3e2cf",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:27.768154Z",
     "start_time": "2025-12-18T12:28:27.759154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_tokenizer_config(save_dir:str)->None:\n",
    "    \"\"\"创建完整的tokenizer配置文件\"\"\"\n",
    "    config = {\n",
    "        \"add_bos_token\": False,\n",
    "        \"add_eos_token\": False,\n",
    "        \"add_prefix_space\": False,\n",
    "        \"bos_token\": \"<|im_start|>\",\n",
    "        \"eos_token\": \"<|im_end|>\",\n",
    "        \"pad_token\": \"<|im_end|>\",\n",
    "        \"unk_token\": \"<unk>\",\n",
    "        \"model_max_length\": 1000000000000000019884624838656,\n",
    "        \"clean_up_tokenization_spaces\": False,\n",
    "        \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
    "        \"chat_template\": (\n",
    "            \"{% for message in messages %}\"\n",
    "            \"{% if message['role'] == 'system' %}\"\n",
    "            \"<|im_start|>system\\n{{ message['content'] }}<|im_end|>\\n\"\n",
    "            \"{% elif message['role'] == 'user' %}\"\n",
    "            \"<|im_start|>user\\n{{ message['content'] }}<|im_end|>\\n\"\n",
    "            \"{% elif message['role'] == 'assistant' %}\"\n",
    "            \"<|im_start|>assistant\\n{{ message['content'] }}<|im_end|>\\n\"\n",
    "            \"{% endif %}\"\n",
    "            \"{% endfor %}\"\n",
    "            \"{% if add_generation_prompt %}\"\n",
    "            \"{{ '<|im_start|>assistant\\n' }}\"\n",
    "            \"{% endif %}\"\n",
    "        )\n",
    "    }\n",
    "    with open(os.path.join(save_dir, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(config, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # 创建special_tokens_map.json\n",
    "    special_tokens_map = {\n",
    "        \"bos_token\": \"<|im_start|>\",\n",
    "        \"eos_token\": \"<|im_end|>\",\n",
    "        \"unk_token\": \"<unk>\",\n",
    "        \"pad_token\": \"<|im_end|>\",\n",
    "        \"additional_special_tokens\": [\"<s>\", \"</s>\"]\n",
    "    }\n",
    "    with open(os.path.join(save_dir, \"special_tokens_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(special_tokens_map, f, ensure_ascii=False, indent=4)"
   ],
   "id": "6bc6f4dbbaf968d0",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:27.798158Z",
     "start_time": "2025-12-18T12:28:27.777158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_tokenizer(data_path: str, save_dir: str, vocab_size: int = 8192) -> None:\n",
    "    \"\"\"\n",
    "    训练一个 tokenizer。\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
    "    tokenizer.normalizer = NFKC()\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\n",
    "    tokenizer.decoder=decoders.ByteLevel()\n",
    "\n",
    "    # 配置特殊token\n",
    "    special_tokens = [\n",
    "        \"<unk>\",\n",
    "        \"<s>\",\n",
    "        \"</s>\",\n",
    "        \"<|im_start|>\",\n",
    "        \"<|im_end|>\"\n",
    "    ]\n",
    "    trainer=trainers.BpeTrainer(\n",
    "        vocab_size=vocab_size,\n",
    "        special_tokens=special_tokens,\n",
    "        show_progress=True,\n",
    "\n",
    "        initial_alphabet=pre_tokenizers.ByteLevel.alphabet(),\n",
    "        min_frequency=2,\n",
    "    )\n",
    "    print(f\"Training tokenizer with data from {data_path}\")\n",
    "    text=read_texts_from_jsonl(data_path)\n",
    "    tokenizer.train_from_iterator(text, trainer=trainer)\n",
    "    # 验证特殊token映射\n",
    "    try:\n",
    "        assert tokenizer.token_to_id(\"<unk>\") == 0\n",
    "        assert tokenizer.token_to_id(\"<s>\") == 1\n",
    "        assert tokenizer.token_to_id(\"</s>\") == 2\n",
    "        assert tokenizer.token_to_id(\"<|im_start|>\") == 3\n",
    "        assert tokenizer.token_to_id(\"<|im_end|>\") == 4\n",
    "    except AssertionError as e:\n",
    "        print(\"Special tokens mapping error:\", e)\n",
    "        raise\n",
    "    tokenizer.save(os.path.join(save_dir, \"tokenizer.json\"))\n",
    "    create_tokenizer_config(save_dir)\n",
    "    print(f\"Tokenizer saved to {save_dir}\")\n"
   ],
   "id": "dbbc4c03e058e751",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:27.813666Z",
     "start_time": "2025-12-18T12:28:27.805158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def eval_tokenizer(tokenizer_path: str) -> None:\n",
    "    \"\"\"评估tokenizer功能\"\"\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading tokenizer: {e}\")\n",
    "        return\n",
    "\n",
    "    # 测试基本属性\n",
    "    print(\"\\n=== Tokenizer基本信息 ===\")\n",
    "    print(f\"Vocab size: {len(tokenizer)}\")\n",
    "    print(f\"Special tokens: {tokenizer.all_special_tokens}\")\n",
    "    print(f\"Special token IDs: {tokenizer.all_special_ids}\")\n",
    "\n",
    "    # 测试聊天模板\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"你是一个AI助手。\"},\n",
    "        {\"role\": \"user\", \"content\": \"How are you?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"I'm fine, thank you. and you?\"},\n",
    "        {\"role\": \"user\", \"content\": \"I'm good too.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"That's great to hear!\"},\n",
    "    ]\n",
    "\n",
    "    print(\"\\n=== 聊天模板测试 ===\")\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        # add_generation_prompt=True\n",
    "    )\n",
    "    print(\"Generated prompt:\\n\", prompt, sep=\"\")\n",
    "\n",
    "    # 测试编码解码\n",
    "    print(\"\\n=== 编码解码测试 ===\")\n",
    "    encoded = tokenizer(prompt, truncation=True, max_length=256)\n",
    "    decoded = tokenizer.decode(encoded[\"input_ids\"], skip_special_tokens=False)\n",
    "    print(\"Decoded text matches original:\", decoded == prompt)\n",
    "\n",
    "    # 测试特殊token处理\n",
    "    print(\"\\n=== 特殊token处理 ===\")\n",
    "    test_text = \"<|im_start|>user\\nHello<|im_end|>\"\n",
    "    encoded = tokenizer(test_text).input_ids\n",
    "    decoded = tokenizer.decode(encoded)\n",
    "    print(f\"Original: {test_text}\")\n",
    "    print(f\"Decoded:  {decoded}\")\n",
    "    print(\"Special tokens preserved:\", decoded == test_text)\n"
   ],
   "id": "6c86dd8e1dc26f24",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:27.860995Z",
     "start_time": "2025-12-18T12:28:27.823236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"./data/mobvoi_seq_monkey_general_open_corpus.jsonl\"\n",
    "save_dir =\"./data/tokenizer_k\"\n",
    "\n",
    "# 训练tokenizer,耗费大量时间,要试试可以打开\n",
    "# train_tokenizer(\n",
    "#     data_path=data_path,\n",
    "#     save_dir=save_dir,\n",
    "#     vocab_size=6144\n",
    "# )\n",
    "\n",
    "# 评估tokenizer\n",
    "eval_tokenizer(save_dir)"
   ],
   "id": "1cbf40c7ecc67da3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tokenizer基本信息 ===\n",
      "Vocab size: 6144\n",
      "Special tokens: ['<|im_start|>', '<|im_end|>', '<unk>', '<s>', '</s>']\n",
      "Special token IDs: [3, 4, 0, 1, 2]\n",
      "\n",
      "=== 聊天模板测试 ===\n",
      "Generated prompt:\n",
      "<|im_start|>system\n",
      "你是一个AI助手。<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "I'm fine, thank you. and you?<|im_end|>\n",
      "<|im_start|>user\n",
      "I'm good too.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "That's great to hear!<|im_end|>\n",
      "\n",
      "\n",
      "=== 编码解码测试 ===\n",
      "Decoded text matches original: True\n",
      "\n",
      "=== 特殊token处理 ===\n",
      "Original: <|im_start|>user\n",
      "Hello<|im_end|>\n",
      "Decoded:  <|im_start|>user\n",
      "Hello<|im_end|>\n",
      "Special tokens preserved: True\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T12:28:27.891818Z",
     "start_time": "2025-12-18T12:28:27.885684Z"
    }
   },
   "cell_type": "markdown",
   "source": "## PretrainDataset",
   "id": "3057b0c769c2ae99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "用于加载已预处理好的数据集。我们继承了torch.utils.data.IterableDataset来定义该数据集，这使得我们可以更灵活、高效地处理数据。",
   "id": "8bf24be4a5d65fca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:00:02.521007Z",
     "start_time": "2025-12-18T13:00:02.504012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "class PretrainDataset(Dataset):\n",
    "    def __init__(self, data_path: str, tokenizer, max_length: int = 512):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.padding=0\n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            self.data = f.readlines()\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 采样一条text\n",
    "        sample=json.loads(self.data[index])\n",
    "        # 拼接bos token\n",
    "        text=f\"{self.tokenizer.bos_token}{sample['text']}\"\n",
    "        # 将文本转为token ID，并截断到max_length长度\n",
    "        input_id = self.tokenizer(text).data['input_ids'][:self.max_length]\n",
    "        # 计算 text 和 padding长度\n",
    "        text_len = len(input_id)\n",
    "        padding_len = self.max_length - text_len\n",
    "\n",
    "         # 5. padding：不足max_length的部分补0，凑齐max_length长度\n",
    "        input_id = input_id + [self.padding] * padding_len\n",
    "        # 6. 生成损失掩码：1表示计算损失，0表示不计算（padding部分）\n",
    "        loss_mask = [1] * text_len + [0] * padding_len\n",
    "\n",
    "        # 自回归训练的输入（X）和目标（Y）\n",
    "        input_id = np.array(input_id)\n",
    "        X = np.array(input_id[:-1]).astype(np.int64)\n",
    "        Y = np.array(input_id[1:]).astype(np.int64)\n",
    "        # 去掉bos就是loss_mask\n",
    "        loss_mask = np.array(loss_mask[1:]).astype(np.int64)\n",
    "\n",
    "        # 8. 转换为PyTorch张量返回\n",
    "        return torch.from_numpy(X), torch.from_numpy(Y), torch.from_numpy(loss_mask)"
   ],
   "id": "9602b7165798ecbb",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SFTDataset",
   "id": "e27bcbfe7fdb55a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "SFTDataset 其实是一个多轮对话数据集，我们的目标是让模型学会如何进行多轮对话。在这个阶段我们的输入是上一轮的对话内容，输出是当前轮的对话内容。\n",
    "\n"
   ],
   "id": "5b1f739caeebee6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "在 SFT 阶段，这里使用的是多轮对话数据集，所以就需要区分哪些位置需要计算损失，哪些位置不需要计算损失。在上面的代码中，我使用了一个 generate_loss_mask 函数来生成 loss_mask。这个函数主要是用来生成 loss_mask，其中 loss_mask 的生成规则是：当遇到 |<im_start|>assistant\\n 时，就开始计算损失，直到遇到 |<im_end|> 为止。这样就可以保证我们的模型在 SFT 阶段只计算当前轮的对话内容，",
   "id": "5fe4a92a7a5ae5d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:05:06.892861Z",
     "start_time": "2025-12-18T13:05:06.871788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SFTDataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, max_length=512):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.padding = 0\n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            self.data = f.readlines()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def generate_loss_mask(self, input_ids):\n",
    "        # 生成 loss mask, 0 表示不计算损失, 1 表示计算损失\n",
    "        mask = [0] * len(input_ids)\n",
    "        a_sequence = [3, 1074, 537, 500, 203]  # <|im_start|>assistant\\n\n",
    "        a_length = len(a_sequence)\n",
    "        n = len(input_ids)\n",
    "        i = 0\n",
    "\n",
    "        while i <= n - a_length:\n",
    "            # 检查当前位置是否匹配目标子序列\n",
    "            match = True\n",
    "            for k in range(a_length):\n",
    "                if input_ids[i + k] != a_sequence[k]:\n",
    "                    match = False\n",
    "                    break\n",
    "            if match:\n",
    "                # 从子序列结束的位置开始查找第一个4, 4 为 <|im_end|> EOS id\n",
    "                j = None\n",
    "                for idx in range(i + a_length, n):\n",
    "                    if input_ids[idx] == 4:\n",
    "                        j = idx\n",
    "                        break\n",
    "                if j is not None:\n",
    "                    start = i + a_length\n",
    "                    end = j  # 结束位置设为j（包含4）\n",
    "                    # 标记区间为1（包括start到end）\n",
    "                    if start <= end:\n",
    "                        for pos in range(start, end + 1):\n",
    "                            if pos < len(mask):\n",
    "                                mask[pos] = 1\n",
    "                # 跳过当前子序列，避免重叠匹配\n",
    "                i += a_length\n",
    "            else:\n",
    "                i += 1\n",
    "        return mask\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        sample = json.loads(self.data[index])\n",
    "        text = self.tokenizer.apply_chat_template(sample, tokenize=False, add_generation_prompt=False)\n",
    "        input_id = self.tokenizer(text).data['input_ids'][:self.max_length]\n",
    "        text_len = len(input_id)\n",
    "        # 没满最大长度的剩余部分\n",
    "        padding_len = self.max_length - text_len\n",
    "        input_id = input_id + [self.padding] * padding_len\n",
    "        # 0表示不计算损失\n",
    "        loss_mask = self.generate_loss_mask(input_id)\n",
    "\n",
    "        input_id = np.array(input_id)\n",
    "        X = np.array(input_id[:-1]).astype(np.int64)\n",
    "        Y = np.array(input_id[1:]).astype(np.int64)\n",
    "        loss_mask = np.array(loss_mask[1:]).astype(np.int64)\n",
    "        return torch.from_numpy(X), torch.from_numpy(Y), torch.from_numpy(loss_mask)\n"
   ],
   "id": "413d4031eef47b3b",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T13:06:13.378865Z",
     "start_time": "2025-12-18T13:06:13.182948Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## 5.3.4 预训练\n",
    "TODO"
   ],
   "id": "dd0ac6a5f7faa097"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7e42360de1fb8165"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
